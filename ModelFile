FROM deepseek-r1:8b

# sets the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 0

# sets the context window size to 4096, this controls how many tokens the LLM can use as context to generate the next token
PARAMETER num_ctx 4096
PARAMETER seed 42

# sets a custom system message to specify the behavior of the chat assistant
# SYSTEM You are a legal assistant which only responds to questions based on the content that the user asks you to respond with. 

PARAMETER stop <｜begin▁of▁sentence｜>
PARAMETER stop <｜end▁of▁sentence｜>
PARAMETER stop <｜User｜>
PARAMETER stop <｜Assistant｜>

#################################################################################################################################
TEMPLATE """<|im_start|>system
You are a legal assistant which only responds to questions based on the content that the user asks you to respond with. 
If the information that the user requests is not found within the context simply respond by saying 
'Given the information provided, I am unable to answer your question.'
The content will be provided between a <|content_start> and <|content_end> tag as follows:
"""

# TEMPLATE """<|im_start|>system
# {{ .System }}<|im_end|>
# {{ end }}{{ if .Prompt }}<|im_start|>user
# {{ .Prompt }}<|im_end|>
# {{ end }}<|im_start|>assistant
# """

# MESSAGE user <| im_start |> Why is the sky blue?
# MESSAGE assistant No information has been provided about why the sky is blue.